# 오리진 서버와 중간 서버: 포워드 프록시와 리버스 프록시

실제로는 클라이언트와 단일한 서버가 한 네트워크 내에 존재하거나 나란히 위치하는 경우는 거의 없습니다.

- 클라이언트와 서버 사이에는 수많은 네트워크 장비들이 있을 수 있으며, 서버를 보완하는 여러 중간 서버들도 함께 존재할 수 있습니다.

클라이언트가 최종적으로 메시지를 주고받는 대상, 우리가 단순히 ‘서버’라고 지칭했던 대상은, 좀 더 정확히 표현하면 자원을 생성하고, 클라이언트에게 권한 있는 응답을 보낼 수 있는 HTTP 서버, 즉 오리진 서버(origin server) 입니다.

## cf) 가용성과 고가용성

- 서버, 네트워크, 특정 하드웨어 부품을 비롯한 컴퓨터 시스템이 주어진 기능을 실제로 수행할 수 있는 시간의 비율을 `가용성(availability)`
- 이 비율이 높을수록 `고가용성(high availability)`이라고 할 수 있으며, 서버의 다중화는 가용성을 높이기 위한 설계 전략

대표적인 HTTP 중간 서버의 유형에는 `프록시(proxy)` 와 `게이트웨이(gateway)` 가 있으며,

- 프록시는 보통 포워드 프록시, 게이트웨이는 리버스 프록시

### 프록시

- 클라이언트가 선택한 메시지 전달의 대리자 역할을 수행
- 보통 캐시 저장, 클라이언트 암호화, 접근 제한 등의 기능을 제공
- 클라이언트가 어떤 프록시를 언제, 어떻게 사용할지 선택하기 때문에, 프록시는 일반적으로 오리진 서버보다 클라이언트에 더 가까이 위치

### 게이트웨이

- 오리진 서버(들)를 향하는 요청 메시지를 먼저 받아서 오리진 서버(들)에게 전달하는 문지기, 또는 경비 역할을 수행
- 게이트웨이는 클라이언트의 요청을 받아 처리하고, 응답도 클라이언트에게 직접 전달
- 일반적으로 클라이언트보다는 오리진 서버에 더 가까이 위치
- 캐시 저장이 가능하며, 부하를 분산시키는 로드 밸런서로서의 역할도 수행 가능

# 고가용성: 로드밸런싱과 스케일링

## 가용성

- `가용성 = 업타임 / (업타임 + 다운타임)`
    - 업타임: 정상적인 사용 시간
    - 다운타임: 어떤 이유로든 정상적인 사용이 불가능한 시간
- 고가용성은 이 수식의 값이 높은 성질, 즉, 전체 사용 시간 중 대부분을 사용할 수 있다는 특성

> 일반적으로 ‘안정적’이라고 평가받는 시스템은 가용성이 99.999%에 이릅니다. 이는 대략 1년에 약 5.26분, 1개월 기준으로는 약 26.3초 정도밖에 다운타임이 발생하지 않는 수준입니다.
> 

### 다운타임은 왜 발생할까?

- 대표적으로 과도한 트래픽으로 인한 서비스 다운, 소프트웨어 상의 예기치 못한 오류, 하드웨어 장애 등으로 발생
- 때로는 보안 공격이나 자연재해가 원인

### 고가용성의 핵심

- 어떤 문제가 발생하더라도 시스템이 계속 동작 가능하도록 설계하는 것, `결함 감내(fault-tolerant)`
- 가장 대표적인 기술은 `다중화(Multi-instance)`, 서버를 다중화하면, 특정 서버에 문제가 생기더라도 다른 예비 서버가 이를 대신해 동작할 수 있기 때문

> 동작 중인 시스템에 문제가 생겼을 때, 예비 시스템으로 자동 전환되는 기능은 페일오버(failover)
> 

## cf) 헬스 체크와 하트비트

서버를 다중화한 경우, 특정 서버에 문제가 생겼을 때 다른 서버가 그 사실을 일반적으로 정기적으로 서버 상태를 검사하는 방법을 사용해 감지

- `헬스 체크(health check)` 라고 하며, 보통 로드 밸런서가 이 기능을 수행
    - HTTP, ICMP 등 다양한 프로토콜을 사용
- `하트비트(heartbeat)` 라는 방법도 존재, 서버 간에 주기적으로 하트비트 메시지를 주고받다가, 신호가 끊기면 문제 발생으로 감지하는 방식

## 로드 밸런싱

가용성에 가장 큰 영향을 끼치는 요인 중 하나는 트래픽 과부하

- 하나의 서버에 과도한 트래픽이 몰릴 경우, 발열, 레이스 컨디션, 메모리 부족 등의 다양한 문제가 발생 가능
- 서버를 여러 대 운영해도, 트래픽이 고르게 분산되지 않으면 가용성은 오히려 저하

트래픽을 고르게 분배할 수 있는 구조가 필요하며, 이를 위한 기술이 바로 `로드 밸런싱(load balancing)`

### 로드 밸런서의 역할

- 로드 밸런서는 다중화된 서버와 클라이언트 사이에 위치하여, 클라이언트의 요청을 균등하게 분배하는 역할
- L4 스위치, L7 스위치 같은 네트워크 장비로 수행할 수도 있지만, 로드 밸런싱 기능을 제공하는 소프트웨어(Nginx, HAProxy 등)를 사용해 일반 서버에서도 구현 가능

> 대표적인 로드 밸런싱 소프트웨어: `HAProxy`, `Envoy`, 웹 서버인 Nginx도 자체적으로 로드 밸런싱 기능을 내장하고 있음
> 

### 로드 밸런싱 알고리즘

서버 간에 부하를 분산할 때, 어떤 방식으로 요청을 분배할지를 결정하는 방법

- 라운드 로빈: 순차적으로 서버에 요청 분배
- 최소 연결(Least Connection): 연결 수가 적은 서버부터 요청 분배
- 랜덤(Random): 임의로 서버를 선택해 분배
- 응답 시간 기반: 응답 시간이 가장 짧은 서버를 선택
- 해시 기반: 요청자 IP나 요청 URL 등을 해시 값으로 변환해 서버 선택

또한 서버 성능이 다를 경우, 각 서버에 `가중치(weight)` 를 부여하여 비율을 조절 가능

- 가중치가 높은 서버는 더 많은 요청을 받도록 설정 가능

## 스케일링: 스케일 업, 스케일 아웃, 오토스케일링

시스템의 성능을 향상시키는 방식은 크게 두 가지

1. 기존 장비를 더 높은 사양으로 교체하는 방식 → 스케일 업 (Scale-Up, 수직 확장)
2. 동일한 장비를 여러 대 구성하는 방식 → 스케일 아웃 (Scale-Out, 수평 확장)

### 스케일 업

- 장점: 설치와 구성이 단순
- 단점: 유연성이 부족하고, 성능의 한계에 도달할 수 있음
    - 계속 더 비싸고 고성능 장비로만 대체할 수밖에 없음

### 스케일 아웃

- 장점: 유연하게 확장/축소 가능
    - 설치와 구성이 다소 복잡할 수 있지만, 한 번 구조를 갖추면 장비 확장이 쉬움
- 병목 현상 완화, 고장 시에도 대응 가능

> 스케일 업은 단일 장비에 의존하므로 장애 발생 시 전체 서비스가 중단될 위험이 큽니다. 반면 스케일 아웃은 여러 대의 서버가 분산되어 있기 때문에 결함 감내에 더 유리합니다
> 

## cf) 오토 스케일링

모든 자원을 트래픽 급증 기준으로 미리 확장하면 비용이 과도하게 발생

- 이를 해결하기 위해, 트래픽이나 시스템 부하에 따라 자동으로 확장/축소하는 기능을 `오토스케일링(auto scaling)`이라고 합니다.
- 오토스케일링을 통해 자원을 더욱 경제적이고 탄력적으로 활용 가능

# Nginx로 알아보는 로드 밸런싱

## Nginx: 대표적인 웹 서버 프로그램

- Nginx는 고성능 웹 서버로, `포워드 프록시`, `리버스 프록시`, `로드 밸런서` 역할까지 수행할 수 있습니다.
- 또한 콘텐츠 캐싱, 보안을 위한 접근 제한, 로드 밸런싱 기능 등을 지원합니다.

## Nginx 설정 구조

Nginx를 설치하면 설정 파일과 디렉터리들이 자동 생성되며, 이 설정 파일들은 Nginx가 어떤 방식으로 동작할지 정의합니다.

- 메인 설정 파일: `/etc/nginx/nginx.conf`
- 가상 호스트 및 로드 밸런싱 설정: `/etc/nginx/conf.d/*.conf`
- 웹 요청 로그: `/var/log/nginx/access.log`
- 에러 로그: `/var/log/nginx/error.log`

```bash
http {
  access_log /var/log/nginx/access.log;
  error_log /var/log/nginx/error.log;

  include /etc/nginx/conf.d/*.conf;
  include /etc/nginx/sites-enabled/*;
}
```

### 로드 밸런싱 설정 예시

```
upstream backend {
  server 10.10.10.2:80 weight=1;
  server 10.10.10.3:80 weight=2;
  server 10.10.10.4:80 backup;
}

server {
  listen 80;
  server_name localhost;

  location / {
    proxy_pass http://backend;
  }
}
```

- `/` 경로로 들어온 요청은 backend 서버 그룹으로 전달됩니다.
- `10.10.10.3`은 `10.10.10.2`보다 두 배 많은 트래픽을 받으며,
- 주 서버에 문제가 생기면 `10.10.10.4`가 백업 서버로 동작합니다.

### 알고리즘 설정 예시

```
upstream backend {
  least_conn;  # 연결 수가 가장 적은 서버 우선
  server 10.10.10.2:80 weight=1;
  server 10.10.10.3:80 weight=2;
  server 10.10.10.4:80 backup;
}
```

## cf) 업스트림 / 다운스트림 vs 인바운드 / 아웃바운드

| 개념 | 설명 |
| --- | --- |
| **업스트림(upstream)** | 클라이언트 → 오리진 서버 방향의 데이터 흐름 |
| **다운스트림(downstream)** | 오리진 서버 → 클라이언트 방향의 데이터 흐름 |
| **인바운드(inbound)** | 외부에서 내부로 들어오는 트래픽 (예: 웹사이트 접속) |
| **아웃바운드(outbound)** | 내부에서 외부로 나가는 트래픽 (예: 외부 API 호출) |

```
업스트림: [클라이언트] → [중간 서버] → [오리진 서버]
다운스트림: [클라이언트] ← [중간 서버] ← [오리진 서버]
```
